# Natural Language Toolkit NLP-Workshop
# Overview
The data corpus that we will be using is a CSV file of Whisper AI transcription of a high school math class. This data is located in my Google Drive, we will use NLTK, Python, and Google Colab to copy and process the file so that it can be analyzed by you during the workshop. From there we will do some basic processing and analysis to extract specific features that give us information about student uncertainty during this math class, based on their conversations and fluctuating sentiment. We will end the workshop with a focus on the important first step of preprocessing our data corpus.
** Issues mounting Google Drive using an Ipad.
## [Module 1 - Introduction](https://github.com/mrhallonline/NLP-Workshop/blob/main/Module_1_Workshop_Setting_Up_Natural_Language_Toolkit_(NLTK)_V3.ipynb) (15 minutes)
1. What do we know?
2. What do we want to know?
3. Some NLP Basics
4. What is feature extraction 
5. Using Google Colab
## [Module 2 - Setting up and Messing Around](https://github.com/mrhallonline/NLP-Workshop/blob/main/Module_2_Workshop_Setting_Up_Natural_Language_Toolkit_(NLTK)_V3.ipynb) (20 minutes)
1. Installing dependencies and libraries
2. Connecting to Google Drive
3. Importing and initial processing of Uncertainty Transcript
4. Some quick analysis
## [Module 3 - Exploration of Basic Analysis](https://github.com/mrhallonline/NLP-Workshop/blob/main/Module_3_Basic_analysis_and_Analysis_Workshop_Natural_Language_Toolkit_(NLTK)_V3.ipynb) (20 minutes)
1. Word counts and sorting
2. Concordance
3. N-grams and collocations
4. Visualizations
## Break (10 minutes)
## [Module 4 - Basic Sentiment Analysis](https://github.com/mrhallonline/NLP-Workshop/blob/main/Module_4_Running_Basic_Sentiment_Analysis_Workshop_Natural_Language_Toolkit_(NLTK)_V3.ipynb) (20 minutes)
1. Setting up
2. Uncertainty words dictionary
3. Looking at sentiment in student uncertainty
4. Change in sentiment over time
5. Listing words by sentiment
6. Linking sentiment to uncertainty
## [Module 5 - Text Wrangling and Preprocessing](https://github.com/mrhallonline/NLP-Workshop/blob/main/Module_5_Basics_of_Text_Preprocessing_Workshop_Natural_Language_Toolkit_(NLTK)_V3.ipynb) (15 minutes)
1. Reconnecting to Google Drive and basic processing
2. Tokenizing Text Using Different Regular Expressions
3. All-in-One Text Normalization Using NLTK
4. Viewing the List of English Stopwords using NLTK
5. List of Ways to Extract Features Using Regular Expression as the tokenizer
## Conclusion (15 minutes)
1. Issues to keep in mind when normalizing your data corpus
2. Potential pitfalls and ethical considerations
3. What did we learn?
